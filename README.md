# ğŸ¤–ğŸ“„ AskMyDocs â€” RAG Chatbot

### RAG Pipeline with FAISS + Streamlit (Local LLM via Ollama)

An end-to-end **Retrieval-Augmented Generation (RAG)** application that allows users to chat with their own documents. The system uses **FAISS** for vector storage, **Streamlit** for a ChatGPT-style UI, and a **local LLM via Ollama (Mistral)** for private, on-device inference.

This project demonstrates a **production-style RAG pipeline** built entirely with open-source tools and local inference â€” no external cloud LLMs required.

---

## ğŸš€ Project Overview

The goal of this project is to build a **privacy-first document intelligence system** that:

* Accepts PDFs and text documents as input
* Converts documents into semantic embeddings
* Stores embeddings in a persistent vector database
* Retrieves relevant context for user queries
* Generates accurate, grounded answers using a local LLM

---

## ğŸ—ï¸ High-Level Architecture

**Data Flow:**

```
Documents (PDF / TXT)
        â†“
Document Loaders (PyPDFLoader / TextLoader)
        â†“
Embedding Model (MiniLM)
        â†“
FAISS Vector Database (Local)
        â†“
Retriever (Semantic Search)
        â†“
Local LLM via Ollama (Mistral)
        â†“
Streamlit Chat UI
```

---

## ğŸ§° Tech Stack

* **LLM (Generation):** Mistral via Ollama
* **Embeddings:** `sentence-transformers/all-MiniLM-L6-v2` (Hugging Face)
* **Vector Database:** FAISS (persistent, local)
* **Frameworks:** LangChain (community + HuggingFace + Ollama integrations)
* **UI:** Streamlit (chat interface + sidebar uploads)
* **Document Loaders:**

  * PyPDFLoader (PDF)
  * TextLoader (TXT)
* **Memory:** ConversationBufferMemory (session-level chat memory)

---

## âœ¨ Key Features

* ğŸ“„ Upload PDFs/TXTs and automatically generate embeddings
* ğŸ’¬ Chat with documents using a ChatGPT-style interface
* â• Incremental knowledge base growth (no overwriting of existing data)
* ğŸ”’ Fully local inference â€” privacy-friendly and offline capable
* ğŸ§  Session memory for coherent multi-turn conversations

---

## ğŸ“ Project Folder Structure

```
rag_project/
â”œâ”€ data/               # Uploaded PDFs/TXTs
â”œâ”€ index/              # FAISS vector DB (persistent)
â”œâ”€ ingest.py           # Ingestion pipeline (embed + store docs)
â”œâ”€ query.py            # Retrieval + generation + memory
â”œâ”€ ui.py               # Streamlit chat application
â”œâ”€ inspect_faiss.py    # FAISS index inspection (optional)
â”œâ”€ requirements.txt    # Project dependencies
â””â”€ venv/               # Python virtual environment
```

---

## âš™ï¸ Getting Started

### ğŸ”§ Environment Setup

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### ğŸ¦™ Install & Run Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
ollama pull mistral
# or
ollama pull gemma:2b
```

---

### â–¶ï¸ Run the Application

```bash
streamlit run ui.py
```

---

## ğŸ§ª How to Use

1. Open the Streamlit app URL in your browser
2. Use **â€œManage Documentsâ€** from the sidebar to upload PDFs or TXTs
3. Ask questions in natural language via the chat interface
4. The system retrieves relevant context from FAISS
5. Answers are generated by the local LLM using retrieved documents
6. Knowledge base grows incrementally with each new upload

---

## ğŸ› ï¸ Implementation Details

### ğŸ”¹ Ingestion Pipeline

* Load documents using PyPDFLoader / TextLoader
* Chunk text and generate embeddings
* Persist embeddings into FAISS index

### ğŸ”¹ Retrieval & Generation

* Semantic search using FAISS retriever
* Context-aware prompting via LangChain
* Answer generation using Ollama-powered local LLM

### ğŸ”¹ Memory Handling

* ConversationBufferMemory stores chat history
* Enables context-aware follow-up questions

---

## ğŸ† Achievements & Outcomes

* âœ… Fully functional RAG pipeline with FAISS
* âœ… ChatGPT-style document Q&A experience
* âœ… Incremental, persistent knowledge base
* âœ… Fully local inference (no cloud LLM dependency)
* âœ… Optional FAISS inspection utility for debugging

---

## ğŸ“Œ Use Cases

* Personal knowledge assistants
* Private document search & Q&A
* Research paper exploration
* Internal documentation chatbots
* Offline AI assistants

---

## ğŸ‘¨â€ğŸ’» Author

**Pavan Mahindrakar** -
Aspiring Data Scientist | AI/ML Enthusiast | Data Engineer

---

â­ *A clean, privacy-first implementation of Retrieval-Augmented Generation using open-source tools and local LLMs.*
